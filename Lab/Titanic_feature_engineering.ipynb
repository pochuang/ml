{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "pred_data = pd.read_csv('test.csv')\n",
    "all_data = pd.concat([train_data,pred_data],axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_Sex_ohe = pd.get_dummies(train_data['Sex'],prefix='Sex')\n",
    "train_data = pd.concat([train_data,train_data_Sex_ohe],axis=1)\n",
    "pred_data_Sex_ohe = pd.get_dummies(pred_data['Sex'],prefix='Sex')\n",
    "pred_data = pd.concat([pred_data,pred_data_Sex_ohe],axis=1)\n",
    "all_data_Sex_ohe = pd.get_dummies(all_data['Sex'],prefix='Sex')\n",
    "all_data = pd.concat([all_data,all_data_Sex_ohe],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data['Cabin'] = all_data['Cabin'].fillna('Unknown')\n",
    "train_data['Cabin'] = train_data['Cabin'].fillna('Unknown')\n",
    "pred_data['Cabin'] = pred_data['Cabin'].fillna('Unknown')\n",
    "all_data['Deck'] = all_data['Cabin'].str.get(0)\n",
    "train_data['Deck'] = train_data['Cabin'].str.get(0)\n",
    "pred_data['Deck'] = pred_data['Cabin'].str.get(0)\n",
    "\n",
    "def hascabin(cb):\n",
    "    if (cb == 'Unknown'):\n",
    "        return 'No'\n",
    "    else:\n",
    "        return 'Yes'\n",
    "    \n",
    "train_data['HasCabin'] = train_data['Cabin'].apply(hascabin)\n",
    "pred_data['HasCabin'] = pred_data['Cabin'].apply(hascabin)\n",
    "all_data['HasCabin'] = all_data['Cabin'].apply(hascabin)\n",
    "\n",
    "train_data_HasCabin_ohe = pd.get_dummies(train_data['HasCabin'],prefix='HasCabin')\n",
    "train_data = pd.concat([train_data,train_data_HasCabin_ohe],axis=1)\n",
    "pred_data_HasCabin_ohe = pd.get_dummies(pred_data['HasCabin'],prefix='HasCabin')\n",
    "pred_data = pd.concat([pred_data,pred_data_HasCabin_ohe],axis=1)\n",
    "all_data_HasCabin_ohe = pd.get_dummies(all_data['HasCabin'],prefix='HasCabin')\n",
    "all_data = pd.concat([all_data,all_data_HasCabin_ohe],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data['Title'] = all_data['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split('.')[0].strip())\n",
    "train_data['Title'] = train_data['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split('.')[0].strip())\n",
    "pred_data['Title'] = pred_data['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split('.')[0].strip())\n",
    "\n",
    "Title_Dict = {}\n",
    "Title_Dict.update(dict.fromkeys(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer'))\n",
    "Title_Dict.update(dict.fromkeys(['Don', 'Sir', 'the Countess', 'Dona', 'Lady'], 'Royalty'))\n",
    "Title_Dict.update(dict.fromkeys(['Mme', 'Ms', 'Mrs'], 'Mrs'))\n",
    "Title_Dict.update(dict.fromkeys(['Mlle', 'Miss'], 'Miss'))\n",
    "Title_Dict.update(dict.fromkeys(['Mr'], 'Mr'))\n",
    "Title_Dict.update(dict.fromkeys(['Master','Jonkheer'], 'Master'))\n",
    "all_data['Title'] = all_data['Title'].map(Title_Dict)\n",
    "train_data['Title'] = train_data['Title'].map(Title_Dict)\n",
    "pred_data['Title'] = pred_data['Title'].map(Title_Dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_Title_ohe = pd.get_dummies(train_data['Title'],prefix='Title')\n",
    "train_data = pd.concat([train_data,train_data_Title_ohe],axis=1)\n",
    "pred_data_Title_ohe = pd.get_dummies(pred_data['Title'],prefix='Title')\n",
    "pred_data = pd.concat([pred_data,pred_data_Title_ohe],axis=1)\n",
    "all_data_Title_ohe = pd.get_dummies(all_data['Title'],prefix='Title')\n",
    "all_data = pd.concat([all_data,all_data_Title_ohe],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data['NameLen'] = all_data.Name.apply(lambda x: x.split('.')[1].strip()).apply(lambda x: len(x))\n",
    "train_data['NameLen'] = train_data.Name.apply(lambda x: x.split('.')[1].strip()).apply(lambda x: len(x))\n",
    "pred_data['NameLen'] = pred_data.Name.apply(lambda x: x.split('.')[1].strip()).apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.loc[train_data['Embarked'].isnull(),'Embarked'] = 'C'\n",
    "all_data.loc[all_data['Embarked'].isnull(),'Embarked'] = 'C'\n",
    "\n",
    "train_data_Embarked_ohe = pd.get_dummies(train_data['Embarked'],prefix='Embarked')\n",
    "train_data = pd.concat([train_data,train_data_Embarked_ohe],axis=1)\n",
    "pred_data_Embarked_ohe = pd.get_dummies(pred_data['Embarked'],prefix='Embarked')\n",
    "pred_data = pd.concat([pred_data,pred_data_Embarked_ohe],axis=1)\n",
    "all_data_Embarked_ohe = pd.get_dummies(all_data['Embarked'],prefix='Embarked')\n",
    "all_data = pd.concat([all_data,all_data_Embarked_ohe],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data['FamilySize'] = all_data['Parch'] + all_data['SibSp'] + 1\n",
    "train_data['FamilySize'] = train_data['Parch'] + train_data['SibSp'] + 1\n",
    "pred_data['FamilySize'] = pred_data['Parch'] + pred_data['SibSp'] + 1\n",
    "\n",
    "def FamilyCat(fs):\n",
    "    if (fs == 1):\n",
    "        return 'Single'\n",
    "    elif (fs >= 2) & (fs <= 4):\n",
    "        return 'SmallFamily'\n",
    "    elif (fs >= 5) & (fs <= 6):\n",
    "        return 'MediumFamily'\n",
    "    elif (fs >= 7):\n",
    "        return 'LargeFamily'\n",
    "\n",
    "all_data['FamilyClass'] = all_data['FamilySize'].apply(FamilyCat)\n",
    "train_data['FamilyClass'] = train_data['FamilySize'].apply(FamilyCat)\n",
    "pred_data['FamilyClass'] = pred_data['FamilySize'].apply(FamilyCat)\n",
    "\n",
    "train_data_FamilyClass_ohe = pd.get_dummies(train_data['FamilyClass'],prefix='FamilyClass')\n",
    "train_data = pd.concat([train_data,train_data_FamilyClass_ohe],axis=1)\n",
    "pred_data_FamilyClass_ohe = pd.get_dummies(pred_data['FamilyClass'],prefix='FamilyClass')\n",
    "pred_data = pd.concat([pred_data,pred_data_FamilyClass_ohe],axis=1)\n",
    "all_data_FamilyClass_ohe = pd.get_dummies(all_data['FamilyClass'],prefix='FamilyClass')\n",
    "all_data = pd.concat([all_data,all_data_FamilyClass_ohe],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if sum(n == 0 for n in train_data.Fare.values.flatten()) > 0:\n",
    "    train_data.loc[train_data.Fare == 0, 'Fare'] = np.nan\n",
    "    train_data['Fare'] = train_data[['Fare']].fillna(train_data.groupby('Pclass').transform('mean'))\n",
    "\n",
    "if sum(n == 0 for n in pred_data.Fare.values.flatten()) > 0:\n",
    "    pred_data.loc[pred_data.Fare == 0, 'Fare'] = np.nan\n",
    "    pred_data['Fare'] = pred_data[['Fare']].fillna(pred_data.groupby('Pclass').transform('mean'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data.loc[all_data['Fare'].isnull(),'Fare'] = np.mean(all_data.loc[all_data['Pclass']==3,'Fare'])\n",
    "pred_data.loc[pred_data['Fare'].isnull(),'Fare'] = np.mean(all_data.loc[all_data['Pclass']==3,'Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Group_Ticket'] = train_data['Fare'].groupby(by=train_data['Ticket']).transform('count')\n",
    "train_data['FareReal'] = train_data['Fare'] / train_data['Group_Ticket']\n",
    "pred_data['Group_Ticket'] = pred_data['Fare'].groupby(by=pred_data['Ticket']).transform('count')\n",
    "pred_data['FareReal'] = pred_data['Fare'] / pred_data['Group_Ticket']\n",
    "all_data['Group_Ticket'] = all_data['Fare'].groupby(by=all_data['Ticket']).transform('count')\n",
    "all_data['FareReal'] = all_data['Fare'] / all_data['Group_Ticket']\n",
    "\n",
    "train_data['UseGT'] = np.where(train_data['Group_Ticket']==1,0 ,1)\n",
    "pred_data['UseGT'] = np.where(pred_data['Group_Ticket']==1,0 ,1)\n",
    "all_data['UseGT'] = np.where(all_data['Group_Ticket']==1,0 ,1)\n",
    "\n",
    "train_data_UseGT_ohe = pd.get_dummies(train_data['UseGT'],prefix='UseGT')\n",
    "train_data = pd.concat([train_data,train_data_UseGT_ohe],axis=1)\n",
    "pred_data_UseGT_ohe = pd.get_dummies(pred_data['UseGT'],prefix='UseGT')\n",
    "pred_data = pd.concat([pred_data,pred_data_UseGT_ohe],axis=1)\n",
    "all_data_UseGT_ohe = pd.get_dummies(all_data['UseGT'],prefix='UseGT')\n",
    "all_data = pd.concat([all_data,all_data_UseGT_ohe],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_Pclass_ohe = pd.get_dummies(train_data['Pclass'],prefix='Pclass')\n",
    "train_data = pd.concat([train_data,train_data_Pclass_ohe],axis=1)\n",
    "pred_data_Pclass_ohe = pd.get_dummies(pred_data['Pclass'],prefix='Pclass')\n",
    "pred_data = pd.concat([pred_data,pred_data_Pclass_ohe],axis=1)\n",
    "all_data_Pclass_ohe = pd.get_dummies(all_data['Pclass'],prefix='Pclass')\n",
    "all_data = pd.concat([all_data,all_data_Pclass_ohe],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.840944318339\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "train_data_age = train_data[['Age','Fare', 'Parch', 'SibSp', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'NameLen', 'Survived']]\n",
    "train_data_age_nn = train_data_age.loc[train_data_age['Age'].notnull()]\n",
    "train_data_age_null = train_data_age.loc[train_data_age['Age'].isnull()]\n",
    "X = train_data_age_nn.values[:,1:]\n",
    "y = train_data_age_nn.values[:,0]\n",
    "rfr = RandomForestRegressor(n_estimators=100)\n",
    "gbr = GradientBoostingRegressor(n_estimators=100,learning_rate=1.0,subsample=0.8)\n",
    "\n",
    "rfr.fit(X,y)\n",
    "print(rfr.score(X,y))\n",
    "\n",
    "train_data_age_pred = rfr.predict(train_data_age_null.values[:,1:].astype(float))\n",
    "train_data.loc[train_data['Age'].isnull(),'Age'] = train_data_age_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818249869644\n"
     ]
    }
   ],
   "source": [
    "all_data_age = all_data[['Age','Fare', 'Parch', 'SibSp','Pclass_1', 'Pclass_2', 'Pclass_3','NameLen']]\n",
    "all_data_age_nn = all_data_age.loc[all_data_age['Age'].notnull()]\n",
    "all_data_age_null = all_data_age.loc[all_data_age['Age'].isnull()]\n",
    "X1 = all_data_age_nn.values[:,1:].astype(float)\n",
    "y1 = all_data_age_nn.values[:,0].astype(float)\n",
    "rfr1 = RandomForestRegressor(n_estimators=200)\n",
    "rfr1.fit(X1,y1)\n",
    "print(rfr1.score(X1,y1))\n",
    "\n",
    "pred_data_age = pred_data[['Age','Fare', 'Parch', 'SibSp', 'Pclass_1', 'Pclass_2', 'Pclass_3','NameLen']]\n",
    "pred_data_age_nn = pred_data_age.loc[pred_data_age['Age'].notnull()]\n",
    "pred_data_age_null = pred_data_age.loc[pred_data_age['Age'].isnull()]\n",
    "pred_data_age_pred = rfr1.predict(pred_data_age_null.values[:,1:].astype(float))\n",
    "pred_data.loc[pred_data['Age'].isnull(),'Age'] = pred_data_age_pred\n",
    "\n",
    "\n",
    "all_data_age_pred = rfr1.predict(all_data_age_null.values[:,1:].astype(float))\n",
    "all_data.loc[all_data['Age'].isnull(),'Age'] = all_data_age_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AgeLevelCat(age):\n",
    "    if (age <= 12):\n",
    "        return 'Children'\n",
    "    elif (age < 18):\n",
    "        return 'Teenager'\n",
    "    elif (age < 40):\n",
    "        return 'Youth'\n",
    "    elif (age < 60):\n",
    "        return 'Middle'\n",
    "    elif (age < 200):\n",
    "        return 'Old'\n",
    "    \n",
    "train_data['AgeLevel'] = train_data['Age'].apply(AgeLevelCat)\n",
    "pred_data['AgeLevel'] = pred_data['Age'].apply(AgeLevelCat)\n",
    "all_data['AgeLevel'] = all_data['Age'].apply(AgeLevelCat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>UseGT_1</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>AgeLevel</th>\n",
       "      <th>AgeLevel_Children</th>\n",
       "      <th>AgeLevel_Middle</th>\n",
       "      <th>AgeLevel_Old</th>\n",
       "      <th>AgeLevel_Teenager</th>\n",
       "      <th>AgeLevel_Youth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Youth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Youth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Youth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Youth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Youth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare       ...       UseGT_1 Pclass_1  \\\n",
       "0      0         A/5 21171   7.2500       ...             0        0   \n",
       "1      0          PC 17599  71.2833       ...             0        1   \n",
       "2      0  STON/O2. 3101282   7.9250       ...             0        0   \n",
       "3      0            113803  53.1000       ...             1        1   \n",
       "4      0            373450   8.0500       ...             0        0   \n",
       "\n",
       "   Pclass_2  Pclass_3 AgeLevel AgeLevel_Children  AgeLevel_Middle  \\\n",
       "0         0         1    Youth                 0                0   \n",
       "1         0         0    Youth                 0                0   \n",
       "2         0         1    Youth                 0                0   \n",
       "3         0         0    Youth                 0                0   \n",
       "4         0         1    Youth                 0                0   \n",
       "\n",
       "   AgeLevel_Old AgeLevel_Teenager  AgeLevel_Youth  \n",
       "0             0                 0               1  \n",
       "1             0                 0               1  \n",
       "2             0                 0               1  \n",
       "3             0                 0               1  \n",
       "4             0                 0               1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_AgeLevel_ohe = pd.get_dummies(train_data['AgeLevel'],prefix='AgeLevel')\n",
    "train_data = pd.concat([train_data,train_data_AgeLevel_ohe],axis=1)\n",
    "pred_data_AgeLevel_ohe = pd.get_dummies(pred_data['AgeLevel'],prefix='AgeLevel')\n",
    "pred_data = pd.concat([pred_data,pred_data_AgeLevel_ohe],axis=1)\n",
    "all_data_AgeLevel_ohe = pd.get_dummies(all_data['AgeLevel'],prefix='AgeLevel')\n",
    "all_data = pd.concat([all_data,all_data_AgeLevel_ohe],axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Mother'] = np.where((train_data['Age'] >= 15) & (train_data['Parch'] >= 1) & (train_data['Sex'] == 'female'),'Yes','No') \n",
    "pred_data['Mother'] = np.where((pred_data['Age'] >= 15) & (pred_data['Parch'] >= 1) & (pred_data['Sex'] == 'female'),'Yes','No') \n",
    "all_data['Mother'] = np.where((all_data['Age'] >= 15) & (all_data['Parch'] >= 1) & (all_data['Sex'] == 'female'),'Yes','No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_Mother_ohe = pd.get_dummies(train_data['Mother'],prefix='Mother')\n",
    "train_data = pd.concat([train_data,train_data_Mother_ohe],axis=1)\n",
    "pred_data_Mother_ohe = pd.get_dummies(pred_data['Mother'],prefix='Mother')\n",
    "pred_data = pd.concat([pred_data,pred_data_Mother_ohe],axis=1)\n",
    "all_data_Mother_ohe = pd.get_dummies(all_data['Mother'],prefix='Mother')\n",
    "all_data = pd.concat([all_data,all_data_Mother_ohe],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_data1 = pd.read_csv('train.csv')\n",
    "pred_data1 = pd.read_csv('test.csv')\n",
    "all_data1 = pd.concat((train_data1,pred_data1))\n",
    "all_data1['FamilyName']=all_data1['Name'].apply(lambda x:x.split(',')[0].strip())\n",
    "\n",
    "\n",
    "train_data['FamilyName'] = all_data1[0:891]['FamilyName']\n",
    "pred_data['FamilyName'] = all_data1[891:]['FamilyName']\n",
    "train_data_FamilyName_ohe = pd.get_dummies(train_data['FamilyName'],prefix='FamilyName')\n",
    "pred_data_FamilyName_ohe = pd.get_dummies(pred_data['FamilyName'],prefix='FamilyName')\n",
    "train_data = pd.concat([train_data,train_data_FamilyName_ohe],axis=1)\n",
    "pred_data = pd.concat([pred_data,pred_data_FamilyName_ohe],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Sex_female',\n",
       "       'Sex_male', 'Deck', 'HasCabin', 'HasCabin_No', 'HasCabin_Yes', 'Title',\n",
       "       'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Officer',\n",
       "       'Title_Royalty', 'NameLen', 'Embarked_C', 'Embarked_Q', 'Embarked_S',\n",
       "       'FamilySize', 'FamilyClass', 'FamilyClass_LargeFamily',\n",
       "       'FamilyClass_MediumFamily', 'FamilyClass_Single',\n",
       "       'FamilyClass_SmallFamily', 'Group_Ticket', 'FareReal', 'UseGT',\n",
       "       'UseGT_0', 'UseGT_1', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'AgeLevel',\n",
       "       'AgeLevel_Children', 'AgeLevel_Middle', 'AgeLevel_Old',\n",
       "       'AgeLevel_Teenager', 'AgeLevel_Youth', 'Mother', 'Mother_No',\n",
       "       'Mother_Yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('titanic_train_data1_orig.csv',index=False,sep=',')\n",
    "pred_data.to_csv('titanic_pred_data1_orig.csv',index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = train_data.drop(['PassengerId','Pclass','Name','Sex','Ticket','Cabin', 'Embarked','Deck','HasCabin','Title','FamilyClass','Group_Ticket','AgeLevel','Mother'],axis=1)\n",
    "pred_data1 = pred_data.drop(['PassengerId','Pclass','Name','Sex','Ticket','Cabin', 'Embarked','Deck','HasCabin','Title','FamilyClass','Group_Ticket','AgeLevel','Mother'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female', 'Sex_male',\n",
       "       'HasCabin_No', 'HasCabin_Yes', 'Title_Master', 'Title_Miss', 'Title_Mr',\n",
       "       'Title_Mrs', 'Title_Officer', 'Title_Royalty', 'NameLen', 'Embarked_C',\n",
       "       'Embarked_Q', 'Embarked_S', 'FamilySize', 'FamilyClass_LargeFamily',\n",
       "       'FamilyClass_MediumFamily', 'FamilyClass_Single',\n",
       "       'FamilyClass_SmallFamily', 'FareReal', 'UseGT', 'UseGT_0', 'UseGT_1',\n",
       "       'Pclass_1', 'Pclass_2', 'Pclass_3', 'AgeLevel_Children',\n",
       "       'AgeLevel_Middle', 'AgeLevel_Old', 'AgeLevel_Teenager',\n",
       "       'AgeLevel_Youth', 'Mother_No', 'Mother_Yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data1.to_csv('titanic_train_data1.csv',index=False,sep=',')\n",
    "pred_data1.to_csv('titanic_pred_data1.csv',index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "AFN_scale = StandardScaler()\n",
    "train_data[['Age','Fare','FareReal','NameLen','FamilySize']] = AFN_scale.fit_transform(train_data[['Age','Fare','FareReal', 'NameLen','FamilySize']])\n",
    "pred_data[['Age','Fare','FareReal','NameLen','FamilySize']] = AFN_scale.fit_transform(pred_data[['Age','Fare','FareReal', 'NameLen','FamilySize']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1_scale = train_data.drop(['PassengerId','Pclass','Name','Sex','Ticket','Cabin', 'Embarked','Deck','HasCabin','Title','FamilyClass','Group_Ticket','AgeLevel','Mother'],axis=1)\n",
    "pred_data1_scale = pred_data.drop(['PassengerId','Pclass','Name','Sex','Ticket','Cabin', 'Embarked','Deck','HasCabin','Title','FamilyClass','Group_Ticket','AgeLevel','Mother'],axis=1)\n",
    "train_data1_scale.to_csv('titanic_train_data1_scale.csv',index=False,sep=',')\n",
    "pred_data1_scale.to_csv('titanic_pred_data1_scale.csv',index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1_orig = pd.read_csv('titanic_train_data1_orig.csv')\n",
    "pred_data1_orig = pd.read_csv('titanic_pred_data1_orig.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['FamName'] = train_data['Name'].apply(lambda x:x.split(',')[0])\n",
    "dead_female_FamName = list(set(train_data[(train_data1_orig.Sex=='female') & (train_data1_orig.Age>=12)\n",
    "                              & (train_data1_orig.Survived==0) & (train_data1_orig.FamilySize>1)]['FamName'].values))\n",
    "survive_male_FamName = list(set(train_data[(train_data1_orig.Sex=='male') & (train_data1_orig.Age>=12)\n",
    "                              & (train_data1_orig.Survived==1) & (train_data1_orig.FamilySize>1)]['FamName'].values))\n",
    "train_data['D_Female_Family'] = np.where(train_data['FamName'].isin(dead_female_FamName),1,0)\n",
    "train_data['S_Male_Family'] = np.where(train_data['FamName'].isin(survive_male_FamName),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data['FamName'] = pred_data['Name'].apply(lambda x:x.split(',')[0])\n",
    "pred_data['D_Female_Family'] = np.where(pred_data['FamName'].isin(dead_female_FamName),1,0)\n",
    "pred_data['S_Male_Family'] = np.where(pred_data['FamName'].isin(survive_male_FamName),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2 = train_data.drop(['PassengerId','Pclass','Name','Sex','Ticket','Cabin', 'Embarked','Deck','HasCabin','Title','FamilyClass','Group_Ticket','AgeLevel','Mother','FamName'],axis=1)\n",
    "pred_data2 = pred_data.drop(['PassengerId','Pclass','Name','Sex','Ticket','Cabin', 'Embarked','Deck','HasCabin','Title','FamilyClass','Group_Ticket','AgeLevel','Mother','FamName'],axis=1)\n",
    "train_data2.to_csv('titanic_train_data2_scale.csv',index=False,sep=',')\n",
    "pred_data2.to_csv('titanic_pred_data2_scale.csv',index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.310638\n",
       "1      1.264392\n",
       "2      2.408897\n",
       "3     -0.261615\n",
       "4     -0.643117\n",
       "5     -1.253519\n",
       "6     -0.032714\n",
       "7     -0.337915\n",
       "8     -0.948318\n",
       "9     -0.719417\n",
       "10    -0.256556\n",
       "11     1.188092\n",
       "12    -0.566816\n",
       "13     2.485197\n",
       "14     1.264392\n",
       "15    -0.490516\n",
       "16     0.348788\n",
       "17    -0.719417\n",
       "18    -0.261615\n",
       "19     1.111791\n",
       "20     1.874795\n",
       "21    -1.635021\n",
       "22     0.904890\n",
       "23    -0.719417\n",
       "24     1.340692\n",
       "25     1.493293\n",
       "26    -0.643117\n",
       "27    -0.604966\n",
       "28     0.806590\n",
       "29    -0.268918\n",
       "         ...   \n",
       "388   -0.719417\n",
       "389   -1.863922\n",
       "390   -0.566816\n",
       "391    1.569593\n",
       "392   -1.329820\n",
       "393    1.264392\n",
       "394   -0.109014\n",
       "395   -0.948318\n",
       "396   -0.490516\n",
       "397    1.340692\n",
       "398   -0.643117\n",
       "399    0.043587\n",
       "400   -0.032714\n",
       "401    0.577689\n",
       "402   -0.643117\n",
       "403   -1.024618\n",
       "404    0.959191\n",
       "405   -0.795717\n",
       "406   -0.566816\n",
       "407    1.493293\n",
       "408   -0.417077\n",
       "409   -2.092823\n",
       "410    1.003966\n",
       "411    0.501389\n",
       "412   -0.185314\n",
       "413    0.591353\n",
       "414    0.653989\n",
       "415    0.615839\n",
       "416   -0.504441\n",
       "417   -0.868771\n",
       "Name: Age, Length: 418, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data2['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
