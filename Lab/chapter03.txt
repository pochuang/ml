--http://alexgkendall.com/computer_vision/bayesian_deep_learning_for_safe_ai
--https://arxiv.org

--GaussianNB(高斯),資料為常態分佈
--MultinomialNB(多類式),用在離散值(1,4,6,7,9)
--BernoulliNB(伯努利),資料為2元值(0,1)

import numpy as np
from sklearn.naive_bayes import GaussianNB
X = np.array([[1,2,3,4,5,6,7,8],
              [1,1,3,4,5,6,6,7],
              [2,1,2,4,5,8,8,8]])
			  
y = np.array([1,2,3])			 

t = np.array([2,2,4,5,6,8,8,8])   --0.19需要2D array,所以需要改為t = np.array([[2,2,4,5,6,8,8,8]])
t1 = np.array([2,3,4,5,6,8,8,8])  --0.19需要2D array,所以需要改為t1 = np.array([[2,3,4,5,6,8,8,8]])

clf = GaussianNB()
clf.fit(X,y)

clf.predict(t)   
--3

clf.predict(t1)
--1

from sklearn.naive_bayes import BernoulliNB
clf = BernoulliNB()
clf.fit(X,y)
clf.predict(t)
--預測結果為1

from sklearn.naive_bayes import MultinomialNB
clf = MultinomialNB(alpha=1.0,class_prior=None,fit_prior=True)
clf.fit(X,y)
clf.predict(t)

--如果改使用t1當作預測值,預測結果為何?(2)
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import BernoulliNB
from sklearn.cross_validation import train_test_split   --將資料分隔為訓練與測試資料集,預設0.75(train)/0.25(test)
from sklearn.metrics import mean_squared_error
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
import pandas as pd
import numpy as np

--請注意winequality-red.csv的所在位置,請自行修改為正確位置
df = pd.read_csv('c:\pyml_scripts\chapter03_naivebayes\winequality-red.csv', header=0, sep=';')

X = df[list(df.columns)[:-1]]
y = df['quality']
X_train, X_test, y_train, y_test = train_test_split(X, y)

modelg = GaussianNB()
modelg.fit(X_train, y_train)
modelg.score(X_test,y_test)
--0.52249999999999996

y_predict = modelg.predict(X_test)

--y_test是真正結果


print "Gaus " + str(modelg.score(X_test, y_test))
mse = mean_squared_error(y_predict, y_test)
print mse ** 0.5

--也可以使用y_predict與y_test直接計算score
from sklearn import metrics
metrics.accuracy_score(y_test,y_predict)


modelm = MultinomialNB()
modelm.fit(X_train, y_train)
y_predict = modelm.predict(X_test)
print "Multi " + str(modelm.score(X_test, y_test))
mse = mean_squared_error(y_predict, y_test)
print mse ** 0.5

modelb = BernoulliNB()
modelb.fit(X_train, y_train)
y_predict = modelb.predict(X_test)
print "Bernoulli " + str(modelb.score(X_test, y_test))
mse = mean_squared_error(y_predict, y_test)
print mse ** 0.5


--如果改用linear regression是否必Naive Bayes更好(score更高)
from sklearn import linear_model
clf = linear_model.LinearRegression()
clf.fit(X_train,y_train)
y_predict = clf.predict(X_test)
print "Linear Regression " + str(clf.score(X_test,y_test))
mse = mean_squared_error(y_predict,y_test)
print mse**0.5

\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\

